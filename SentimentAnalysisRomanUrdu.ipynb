{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADVANCED DATA SCIENCE PROJECT - SENTIMENT ANALYSIS OF ROMAN URDU TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Background</h5>\n",
    "Sentiment analysis is part of natural language processing that aims to determine the sentiments of a text, mostly as positive or negative. Most sentiment analysis is based on languages with rich resources like English. However, there is a gap when it comes to Roman urdu which is very popular and widely used on social media platforms by people of India and Paksitan. A well developed model will allow us to understand users' sentiments towards products, services or events providing audience insights which may be used to build systems like a recommendation system.\n",
    "\n",
    "<h5>Objective</h5>\n",
    "To delve deeper insights into text data written in Roman urdu, this project will take a previously tagged open dataset and use it to train a sentiment analysis model using machine learning and deep learning algorithms.\n",
    "\n",
    "<h5>Data Source</h5>\n",
    "Open Dataset. It contains roman urdu text from reviews of various e-commerce website, comments of public facebook pages, and twitter accounts. It is tagged for positive, negative and neutral comments. Link : https://archive.ics.uci.edu/ml/datasets/Roman+Urdu+Data+Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. INITIAL DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries for Initial data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sai kha ya her kisi kay bus ki bat nhi hai lak...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sahi bt h</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kya bt hai,</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wah je wah</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are wha kaya bat hai</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comments Sentiment Extra\n",
       "0  Sai kha ya her kisi kay bus ki bat nhi hai lak...  Positive   NaN\n",
       "1                                          sahi bt h  Positive   NaN\n",
       "2                                        Kya bt hai,  Positive   NaN\n",
       "3                                         Wah je wah  Positive   NaN\n",
       "4                               Are wha kaya bat hai  Positive   NaN"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#READ DATA INTO PANDAS DATAFRAME\n",
    "df=pd.read_csv(\"Roman Urdu DataSet.csv\", names=[\"Comments\", \"Sentiment\",\"Extra\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify quality issues (e.g. missing values, wrong measurements), assess feature quality and value distribution of data - We use simple metrics to understand distribution of data and identify any discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20229"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INITIAL LENGTH OF DATA\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Neutral', 'Negative', 'Neative'], dtype=object)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UNIQUE VALUES IN SENTIMENT COLUMN\n",
    "df['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '----------------', '----------', '-------', '------', '9090',\n",
       "       'till here'], dtype=object)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UNIQUE VALUES IN EXTRA COLUMN \n",
    "df['Extra'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the above results, we need to make two data cleaning efforts:\n",
    "\n",
    "1) There seems to be spelling mistake with the sentiment \"Neative\". Lets see how frequent is this mistake. We can decide to either delete it or keep it. We find that there is no Nan value in this column.\n",
    "\n",
    "2) The last column seem to contain no useful information. Hence we will delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     8929\n",
       "Positive    6013\n",
       "Negative    5286\n",
       "Neative        1\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing distribution of sentiment class through a bar chart\n",
    "df['Sentiment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. DATA CLEANSING - REMOVING DUPLICATES, NAN VALUES AND ERRORSOME DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniquesentences=set(df['Comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19665"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniquesentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##This means the data has duplicate sentences. Let's remove the duplicates and any nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19665"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset='Comments')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sai kha ya her kisi kay bus ki bat nhi hai lak...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sahi bt h</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kya bt hai,</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wah je wah</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are wha kaya bat hai</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comments Sentiment\n",
       "0  Sai kha ya her kisi kay bus ki bat nhi hai lak...  Positive\n",
       "1                                          sahi bt h  Positive\n",
       "2                                        Kya bt hai,  Positive\n",
       "3                                         Wah je wah  Positive\n",
       "4                               Are wha kaya bat hai  Positive"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets delete the last column extra, any Neative sentence and nan values\n",
    "df=df.drop(columns=['Extra'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19664"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DROP NAN\n",
    "df=df.dropna()\n",
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19663"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REMOVE ROW WITH SPELLING ERROR\n",
    "df = df[df.Sentiment != 'Neative']\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19658</th>\n",
       "      <td>20224</td>\n",
       "      <td>Hamari jese awam teli laga k mazay leti</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19659</th>\n",
       "      <td>20225</td>\n",
       "      <td>Kaash hum b parhay likhay hotayKabhi likhtay g...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>20226</td>\n",
       "      <td>Bahi sayasat kufrrr ha saaaf bttttt ha qanon s...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19661</th>\n",
       "      <td>20227</td>\n",
       "      <td>aanti toh gussa e kr gai hain</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19662</th>\n",
       "      <td>20228</td>\n",
       "      <td>mai b sirf shadi kanry ki waja say imran khan ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                           Comments Sentiment\n",
       "19658  20224           Hamari jese awam teli laga k mazay leti   Negative\n",
       "19659  20225  Kaash hum b parhay likhay hotayKabhi likhtay g...  Negative\n",
       "19660  20226  Bahi sayasat kufrrr ha saaaf bttttt ha qanon s...  Negative\n",
       "19661  20227                     aanti toh gussa e kr gai hain   Negative\n",
       "19662  20228  mai b sirf shadi kanry ki waja say imran khan ...  Positive"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.reset_index()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19658</th>\n",
       "      <td>Hamari jese awam teli laga k mazay leti</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19659</th>\n",
       "      <td>Kaash hum b parhay likhay hotayKabhi likhtay g...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>Bahi sayasat kufrrr ha saaaf bttttt ha qanon s...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19661</th>\n",
       "      <td>aanti toh gussa e kr gai hain</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19662</th>\n",
       "      <td>mai b sirf shadi kanry ki waja say imran khan ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comments Sentiment\n",
       "19658           Hamari jese awam teli laga k mazay leti   Negative\n",
       "19659  Kaash hum b parhay likhay hotayKabhi likhtay g...  Negative\n",
       "19660  Bahi sayasat kufrrr ha saaaf bttttt ha qanon s...  Negative\n",
       "19661                     aanti toh gussa e kr gai hain   Negative\n",
       "19662  mai b sirf shadi kanry ki waja say imran khan ...  Positive"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(columns=['index'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After some initial data cleansing, we have 19663 rows of data - comments and respective sentiments (positive, negative, neutral).\n",
    "### 3. PREPROCESSING for FEATURE CREATION\n",
    "\n",
    "#### Given we have textual data which is based on natural language, we will import nltk libary to remove some stop words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 6.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click (from nltk)\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl\n",
      "Collecting joblib (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/dd/0e015051b4a27ec5a58b02ab774059f3289a94b0906f880a3f9507e74f38/joblib-0.16.0-py3-none-any.whl (300kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 8.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/f2/b3af9ce9df4b7e121dfeece41fc95e37b14f0153821f35d08edb0b0813ff/regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660kB)\n",
      "\u001b[K     |████████████████████████████████| 665kB 6.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/7e/281edb5bc3274dfb894d90f4dbacfceaca381c2435ec6187a2c6f329aed7/tqdm-4.48.2-py2.py3-none-any.whl (68kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 6.0MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "Successfully built nltk\n",
      "Installing collected packages: click, joblib, regex, tqdm, nltk\n",
      "Successfully installed click-7.1.2 joblib-0.16.0 nltk-3.5 regex-2020.7.14 tqdm-4.48.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Stop word removal</h3> - A list of stop word is usually available for many languages but since roman urdu is not well researched, based on prior knowledge, we will consider all single letters as stop words since these do not carry sentiment meaning. We also use a stopword list found on github. https://github.com/haseebelahi/roman-urdu-stopwords/blob/master/stopwords.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REMOVING SINGLE LETTERs and symbols, punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(0,19663):\n",
    "    review = re.sub('[^a-zA-Z]',' ',df.iloc[:,0].values[i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[word for word in review if len(word)>1] ##REMOVING SINGLE LETTERS\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REMOVING STOP WORDS BASED ON LIST AVAILABLE ON GITHUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcorpus=[]\n",
    "stopwords=['ai', 'ayi', 'hy', 'hai', 'main', 'ki', 'tha', 'koi', 'ko', 'sy', 'woh', 'bhi', 'aur', 'wo', 'yeh', 'rha', 'hota', 'ho', 'ga', 'ka', 'le', 'lye', 'kr', 'kar', 'lye', 'liye', 'hotay', 'waisay', 'gya', 'gaya', 'kch', 'ab', 'thy', 'thay', 'houn', 'hain', 'han', 'to', 'is', 'hi', 'jo', 'kya', 'thi', 'se', 'pe', 'phr', 'wala', 'waisay', 'us', 'na', 'ny', 'hun', 'rha', 'raha', 'ja', 'rahay', 'abi', 'uski', 'ne', 'haan', 'acha', 'nai', 'sent', 'photo', 'you', 'kafi', 'gai', 'rhy', 'kuch', 'jata', 'aye', 'ya', 'dono', 'hoa', 'aese', 'de', 'wohi', 'jati', 'jb', 'krta', 'lg', 'rahi', 'hui', 'karna', 'krna', 'gi', 'hova', 'yehi', 'jana', 'jye', 'chal', 'mil', 'tu', 'hum', 'par', 'hay', 'kis', 'sb', 'gy', 'dain', 'krny', 'tou']\n",
    "for i in range(0,19663):\n",
    "    review = corpus[i]\n",
    "    review=review.split()\n",
    "    review=[word for word in review if not word in stopwords]\n",
    "    review=' '.join(review)\n",
    "    newcorpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Comparing results. If you compare the sentence with and without stop word removal, we can see that we have successfully removed all single letter words, symbols, punctuations and other stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bht shukria rna m apni dil diyan gallan kisko sunato😅'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Before removal\n",
    "df.iloc[283,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bht shukria rna apni dil diyan gallan kisko sunato'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After removal\n",
    "newcorpus[283]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> MORE CLEANING - Some rows may have empty strings given we have removed some words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newcorpus[newcorpus == '']) #Some rows may have empty strings given we have removed some words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> 75 rows identified with empty strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sentiment column is a categorical column with three categories, Positive, Negative and Neutral. Lets encode it as a numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentencoded=df.iloc[:,1].values\n",
    "label_sentiment=LabelEncoder()\n",
    "sentimentencoded=label_sentiment.fit_transform(sentimentencoded)\n",
    "# 0 is negative, 1 is neutral and 2 is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments_Corpus</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sai kha her kisi kay bus bat nhi lakin hal kal...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sahi bt</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bt</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wah je wah</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are wha kaya bat</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Comments_Corpus  Sentiment_Encoded  \\\n",
       "0  sai kha her kisi kay bus bat nhi lakin hal kal...                  2   \n",
       "1                                            sahi bt                  2   \n",
       "2                                                 bt                  2   \n",
       "3                                         wah je wah                  2   \n",
       "4                                   are wha kaya bat                  2   \n",
       "\n",
       "  Sentiment  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2  Positive  \n",
       "3  Positive  \n",
       "4  Positive  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MMERGING THE COMMENTS CORPUS WITH ENCODEDE SENTIMENTS\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "dfnew1 = DataFrame (newcorpus,columns=['Comments_Corpus'])\n",
    "dfnew2 = DataFrame (sentimentencoded,columns=['Sentiment_Encoded'])\n",
    "dfnew1= dfnew1.join(dfnew2)\n",
    "dfnew1['Sentiment']=df['Sentiment']\n",
    "dfnew1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> REMOVING EMPTY STRINGS DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew1['Comments_Corpus'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19517"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew1=dfnew1.dropna()\n",
    "dfnew1.tail()\n",
    "len(dfnew1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Comments_Corpus</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19512</th>\n",
       "      <td>19658</td>\n",
       "      <td>hamari jese awam teli laga mazay leti</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19513</th>\n",
       "      <td>19659</td>\n",
       "      <td>kaash parhay likhay hotaykabhi likhtay gulbada...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19514</th>\n",
       "      <td>19660</td>\n",
       "      <td>bahi sayasat kufrrr ha saaaf bttttt ha qanon s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19515</th>\n",
       "      <td>19661</td>\n",
       "      <td>aanti toh gussa</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19516</th>\n",
       "      <td>19662</td>\n",
       "      <td>mai sirf shadi kanry waja say imran khan sat dey</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                    Comments_Corpus  \\\n",
       "19512  19658              hamari jese awam teli laga mazay leti   \n",
       "19513  19659  kaash parhay likhay hotaykabhi likhtay gulbada...   \n",
       "19514  19660  bahi sayasat kufrrr ha saaaf bttttt ha qanon s...   \n",
       "19515  19661                                    aanti toh gussa   \n",
       "19516  19662   mai sirf shadi kanry waja say imran khan sat dey   \n",
       "\n",
       "       Sentiment_Encoded Sentiment  \n",
       "19512                  0  Negative  \n",
       "19513                  0  Negative  \n",
       "19514                  0  Negative  \n",
       "19515                  0  Negative  \n",
       "19516                  2  Positive  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew1=dfnew1.reset_index()\n",
    "dfnew1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew1=dfnew1.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVING THE CLEAN DATA TO A CSV FILE FOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments_Corpus</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19512</th>\n",
       "      <td>hamari jese awam teli laga mazay leti</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19513</th>\n",
       "      <td>kaash parhay likhay hotaykabhi likhtay gulbada...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19514</th>\n",
       "      <td>bahi sayasat kufrrr ha saaaf bttttt ha qanon s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19515</th>\n",
       "      <td>aanti toh gussa</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19516</th>\n",
       "      <td>mai sirf shadi kanry waja say imran khan sat dey</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Comments_Corpus  Sentiment_Encoded  \\\n",
       "19512              hamari jese awam teli laga mazay leti                  0   \n",
       "19513  kaash parhay likhay hotaykabhi likhtay gulbada...                  0   \n",
       "19514  bahi sayasat kufrrr ha saaaf bttttt ha qanon s...                  0   \n",
       "19515                                    aanti toh gussa                  0   \n",
       "19516   mai sirf shadi kanry waja say imran khan sat dey                  2   \n",
       "\n",
       "      Sentiment  \n",
       "19512  Negative  \n",
       "19513  Negative  \n",
       "19514  Negative  \n",
       "19515  Negative  \n",
       "19516  Positive  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew1.to_csv('CleanData.csv')   #SAVING THE CLEAN DATA TO A CSV FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tokenizing - transforming the data to create feature Vectors based on the corpus above using Scikit-learn's CountVectorizer.\n",
    "This is a type of one hot encoding where each record will have ones for words (divided into multiple columns) they contain and zeros for words that they do not contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfnew1=pd.read_csv('CleanData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcorpus=dfnew1['Comments_Corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(max_features=250, ngram_range=(1,2))\n",
    "commentsasvectors=cv.fit_transform(newcorpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentsasvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> We have succesfully performed ETL. Extracted the data, tranformed the data into feature vectors and loaded for training use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'namoona word bolungi unhe ek ghoori deni mujhe fouran waise aunty thanks bolin'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10000th comment\n",
    "newcorpus[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # number of words in 10000th comment\n",
    "np.sum(commentsasvectors[10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. MODEL 1 - MACHINE LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DEFINING INDEPENDENT VARIABLES (COMMENTS) AND DEPENDENT VARIABLES (SENTIMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=commentsasvectors\n",
    "y=dfnew1['Sentiment_Encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN TEST SPLIT DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACHINE LEARNING CLASSIFIERS - MULTI CLASS LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR=LogisticRegression(C=0.01,solver='liblinear',multi_class='auto')\n",
    "LR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.5332991803278688 \n"
     ]
    }
   ],
   "source": [
    "print('Accuracy is {} '.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy score of 53.3% is not very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 184  790   94]\n",
      " [  43 1523  133]\n",
      " [  66  696  375]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "labels=['Negative','Neutral','Positive']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier \\n')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 MACHINE LEARNING CLASSIFIERS - LOGISTIC REGRESSION - USING ONLY POSITVE AND NEGATIVE SENTIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SLICED DATA WITH JUST POLAR SENTIMENTS - POSITIVE AND NEGATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11091"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwithoutneutral=dfnew1[dfnew1.Sentiment != 'Neutral']\n",
    "len(dfwithoutneutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments_Corpus</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19512</th>\n",
       "      <td>hamari jese awam teli laga mazay leti</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19513</th>\n",
       "      <td>kaash parhay likhay hotaykabhi likhtay gulbada...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19514</th>\n",
       "      <td>bahi sayasat kufrrr ha saaaf bttttt ha qanon s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19515</th>\n",
       "      <td>aanti toh gussa</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19516</th>\n",
       "      <td>mai sirf shadi kanry waja say imran khan sat dey</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Comments_Corpus  Sentiment_Encoded  \\\n",
       "19512              hamari jese awam teli laga mazay leti                  0   \n",
       "19513  kaash parhay likhay hotaykabhi likhtay gulbada...                  0   \n",
       "19514  bahi sayasat kufrrr ha saaaf bttttt ha qanon s...                  0   \n",
       "19515                                    aanti toh gussa                  0   \n",
       "19516   mai sirf shadi kanry waja say imran khan sat dey                  2   \n",
       "\n",
       "      Sentiment  \n",
       "19512  Negative  \n",
       "19513  Negative  \n",
       "19514  Negative  \n",
       "19515  Negative  \n",
       "19516  Positive  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwithoutneutral.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments_Corpus</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11086</th>\n",
       "      <td>hamari jese awam teli laga mazay leti</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11087</th>\n",
       "      <td>kaash parhay likhay hotaykabhi likhtay gulbada...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>bahi sayasat kufrrr ha saaaf bttttt ha qanon s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>aanti toh gussa</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>mai sirf shadi kanry waja say imran khan sat dey</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Comments_Corpus  Sentiment_Encoded  \\\n",
       "11086              hamari jese awam teli laga mazay leti                  0   \n",
       "11087  kaash parhay likhay hotaykabhi likhtay gulbada...                  0   \n",
       "11088  bahi sayasat kufrrr ha saaaf bttttt ha qanon s...                  0   \n",
       "11089                                    aanti toh gussa                  0   \n",
       "11090   mai sirf shadi kanry waja say imran khan sat dey                  2   \n",
       "\n",
       "      Sentiment  \n",
       "11086  Negative  \n",
       "11087  Negative  \n",
       "11088  Negative  \n",
       "11089  Negative  \n",
       "11090  Positive  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwithoutneutral.reset_index(inplace=True)\n",
    "dfwithoutneutral=dfwithoutneutral.drop(columns=['index'])\n",
    "dfwithoutneutral.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ENCODING IT AGAIN TO JUST HAVE 0 AND 1 IN A NEW COLUMN MARKED AS Sentiment_Encoded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentencoded2=dfwithoutneutral.iloc[:,2].values\n",
    "label_sentiment2=LabelEncoder()\n",
    "sentimentencoded2=label_sentiment2.fit_transform(sentimentencoded2)\n",
    "# 0 is negative , 1 is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentencoded2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwithoutneutral['Sentiment_Encoded_new']=sentimentencoded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments_Corpus</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Encoded_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11086</th>\n",
       "      <td>hamari jese awam teli laga mazay leti</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11087</th>\n",
       "      <td>kaash parhay likhay hotaykabhi likhtay gulbada...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>bahi sayasat kufrrr ha saaaf bttttt ha qanon s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>aanti toh gussa</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>mai sirf shadi kanry waja say imran khan sat dey</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Comments_Corpus  Sentiment_Encoded  \\\n",
       "11086              hamari jese awam teli laga mazay leti                  0   \n",
       "11087  kaash parhay likhay hotaykabhi likhtay gulbada...                  0   \n",
       "11088  bahi sayasat kufrrr ha saaaf bttttt ha qanon s...                  0   \n",
       "11089                                    aanti toh gussa                  0   \n",
       "11090   mai sirf shadi kanry waja say imran khan sat dey                  2   \n",
       "\n",
       "      Sentiment  Sentiment_Encoded_new  \n",
       "11086  Negative                      0  \n",
       "11087  Negative                      0  \n",
       "11088  Negative                      0  \n",
       "11089  Negative                      0  \n",
       "11090  Positive                      1  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwithoutneutral.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SAVING DATA WITHOUT NEUTRAL COMMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwithoutneutral.to_csv('Cleandatawithoutneutral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfwithoutneutral=pd.read_csv('Cleandatawithoutneutral.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOKENIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOKENIZING\n",
    "newcorpus=dfwithoutneutral['Comments_Corpus']\n",
    "cv=CountVectorizer(max_features=1000, ngram_range=(1,2))\n",
    "commentsasvectors=cv.fit_transform(newcorpus).toarray()\n",
    "x=commentsasvectors\n",
    "y=dfwithoutneutral['Sentiment_Encoded_new']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGICTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7169896349707076 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "LR=LogisticRegression(C=0.01,solver='liblinear')\n",
    "LR.fit(x_train,y_train)\n",
    "y_pred=LR.predict(x_test)\n",
    "print('Accuracy is {} '.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that if we only include positive and negative sentiments to train our model, the accuracy improves to 71.7%, which is not that great but much better than previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL EVALUATION : The accuracy score for the model with only positive and negative sentiments is higher (71.7%) than when neutral comments are included (only 53%). THe confusion matrix represents the true vs predicted values. We can see that it does give a reasonable amount of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[769 267]\n",
      " [361 822]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "labels=['Negative','Positive']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier \\n')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MODEL 2 - DEEP LEARNING - KERAS SEQUENTIAL MODEL\n",
    "We will now use a deep learning model to train our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Flatten, Input\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew1=pd.read_csv('CleanData.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reiterating some data preprocessing \n",
    "Removing very long comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comments_Corpus</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>total_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sai kha her kisi kay bus bat nhi lakin hal kal...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sahi bt</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bt</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wah je wah</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>are wha kaya bat</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    Comments_Corpus  \\\n",
       "0           0  sai kha her kisi kay bus bat nhi lakin hal kal...   \n",
       "1           1                                            sahi bt   \n",
       "2           2                                                 bt   \n",
       "3           3                                         wah je wah   \n",
       "4           4                                   are wha kaya bat   \n",
       "\n",
       "   Sentiment_Encoded Sentiment  total_words  \n",
       "0                  2  Positive           19  \n",
       "1                  2  Positive            2  \n",
       "2                  2  Positive            1  \n",
       "3                  2  Positive            3  \n",
       "4                  2  Positive            4  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew1['total_words'] = dfnew1['Comments_Corpus'].str.count(' ') + 1\n",
    "dfnew1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(dfnew1.total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4      1854\n",
       "3      1778\n",
       "5      1775\n",
       "6      1629\n",
       "2      1366\n",
       "       ... \n",
       "134       1\n",
       "102       1\n",
       "86        1\n",
       "133       1\n",
       "103       1\n",
       "Name: total_words, Length: 103, dtype: int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew1['total_words'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Few sentences are really very long and we will remove these for a better uniform analysis. We will use a cut off of 25 words per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18229"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew1 = dfnew1[dfnew1.total_words < 25]\n",
    "len(dfnew1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments_Corpus</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>total_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18224</th>\n",
       "      <td>hamari jese awam teli laga mazay leti</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18225</th>\n",
       "      <td>kaash parhay likhay hotaykabhi likhtay gulbada...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18226</th>\n",
       "      <td>bahi sayasat kufrrr ha saaaf bttttt ha qanon s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18227</th>\n",
       "      <td>aanti toh gussa</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18228</th>\n",
       "      <td>mai sirf shadi kanry waja say imran khan sat dey</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Comments_Corpus  Sentiment_Encoded  \\\n",
       "18224              hamari jese awam teli laga mazay leti                  0   \n",
       "18225  kaash parhay likhay hotaykabhi likhtay gulbada...                  0   \n",
       "18226  bahi sayasat kufrrr ha saaaf bttttt ha qanon s...                  0   \n",
       "18227                                    aanti toh gussa                  0   \n",
       "18228   mai sirf shadi kanry waja say imran khan sat dey                  2   \n",
       "\n",
       "      Sentiment  total_words  \n",
       "18224  Negative            7  \n",
       "18225  Negative            8  \n",
       "18226  Negative           18  \n",
       "18227  Negative            3  \n",
       "18228  Positive           10  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew1=dfnew1.drop(columns=['index'])\n",
    "dfnew1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Since sentimentclass is multiclass, we will onehot encode it using get_dummies command in pandas. This will results in three columns, each for category negative, neutral and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcorpus=dfnew1['Comments_Corpus']\n",
    "sentimentclass=dfnew1['Sentiment_Encoded']\n",
    "Y=pd.get_dummies(sentimentclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> TEST TRAIN SPLIT - We will stratitfy because the number of samples for each sentiment class is uneven (neutral is highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train,x_test,y_train,y_test=train_test_split(newcorpus,sentimentclass,test_size=0.20, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(newcorpus,Y,test_size=0.20, stratify=sentimentclass, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> TOKENIZING - USING KERAS TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_obj=Tokenizer()\n",
    "total_comments = newcorpus\n",
    "tokenizer_obj.fit_on_texts(total_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad_sequences\n",
    "max_length= max([len(s.split()) for s in total_comments])\n",
    "\n",
    "#vocabulary size\n",
    "vocab_size=len(tokenizer_obj.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26853"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens=tokenizer_obj.texts_to_sequences(x_train)\n",
    "x_test_tokens=tokenizer_obj.texts_to_sequences(x_test)\n",
    "\n",
    "x_train_pad=pad_sequences(x_train_tokens, maxlen=max_length, padding='post')\n",
    "x_test_pad=pad_sequences(x_test_tokens, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEQUENTIAL MODEL - for multiclass output, we use softmax activation, categorical crossentroy for loss, and rmsprop as an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=100\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=max_length))\n",
    "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax')) # we will have three outputs\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 24, 100)           2685300   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 32)                12768     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 2,698,167\n",
      "Trainable params: 2,698,167\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14583 samples, validate on 3646 samples\n",
      "Epoch 1/5\n",
      " - 239s - loss: 0.2948 - acc: 0.8995 - val_loss: 1.0558 - val_acc: 0.6306\n",
      "Epoch 2/5\n",
      " - 236s - loss: 0.2682 - acc: 0.9093 - val_loss: 1.0686 - val_acc: 0.6234\n",
      "Epoch 3/5\n",
      " - 229s - loss: 0.2477 - acc: 0.9168 - val_loss: 1.1320 - val_acc: 0.6251\n",
      "Epoch 4/5\n",
      " - 238s - loss: 0.2273 - acc: 0.9248 - val_loss: 1.1801 - val_acc: 0.6267\n",
      "Epoch 5/5\n",
      " - 233s - loss: 0.2095 - acc: 0.9296 - val_loss: 1.1566 - val_acc: 0.6264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46cdbf9518>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad,y_train, epochs=5, batch_size=32, validation_data=(x_test_pad,y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to get an accuracy around 62%, which is not that great and does not improve much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 USING DEEP LEARNING on just positive and negative comments. The data is unevenly distributed with neutral comments dominating the dataset. However, data for positive and negative sentiment is comparable size. We expect the model to perform better on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwithoutneutral=pd.read_csv('Cleandatawithoutneutral.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comments_Corpus</th>\n",
       "      <th>Sentiment_Encoded</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Encoded_new</th>\n",
       "      <th>total_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sai kha her kisi kay bus bat nhi lakin hal kal...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sahi bt</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bt</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wah je wah</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>are wha kaya bat</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    Comments_Corpus  \\\n",
       "0           0  sai kha her kisi kay bus bat nhi lakin hal kal...   \n",
       "1           1                                            sahi bt   \n",
       "2           2                                                 bt   \n",
       "3           3                                         wah je wah   \n",
       "4           4                                   are wha kaya bat   \n",
       "\n",
       "   Sentiment_Encoded Sentiment  Sentiment_Encoded_new  total_words  \n",
       "0                  2  Positive                      1           19  \n",
       "1                  2  Positive                      1            2  \n",
       "2                  2  Positive                      1            1  \n",
       "3                  2  Positive                      1            3  \n",
       "4                  2  Positive                      1            4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwithoutneutral['total_words'] = dfwithoutneutral['Comments_Corpus'].str.count(' ') + 1\n",
    "dfwithoutneutral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10104"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwithoutneutral = dfwithoutneutral[dfwithoutneutral.total_words < 25]\n",
    "len(dfwithoutneutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwithoutneutral.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> We dont need to one hot encode sentiment_encoded_new as it is already binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcorpus=dfwithoutneutral['Comments_Corpus']\n",
    "sentimentclass=dfwithoutneutral['Sentiment_Encoded_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will stratitfy because...\n",
    "x_train,x_test,y_train,y_test=train_test_split(newcorpus,sentimentclass,test_size=0.20, stratify=sentimentclass, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20089"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_obj=Tokenizer()\n",
    "total_comments = newcorpus\n",
    "tokenizer_obj.fit_on_texts(total_comments)\n",
    "\n",
    "#pad_sequences\n",
    "max_length= max([len(s.split()) for s in total_comments])\n",
    "\n",
    "#vocabulary size\n",
    "vocab_size=len(tokenizer_obj.word_index) + 1\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens=tokenizer_obj.texts_to_sequences(x_train)\n",
    "x_test_tokens=tokenizer_obj.texts_to_sequences(x_test)\n",
    "\n",
    "x_train_pad=pad_sequences(x_train_tokens, maxlen=max_length, padding='post')\n",
    "x_test_pad=pad_sequences(x_test_tokens, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> SEQUENTIAL MODEL - WE USE SIGMOID ACTIVATION, BINARY_CROSSENTROPY FOR LOSS AND ADAM OPTIMIZER SINCE IT IS A BINARY OUTPUT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=100\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=max_length))\n",
    "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_callbacks = [\n",
    "    #tf.keras.callbacks.EarlyStopping(patience=2),\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 2021 samples\n",
      "Epoch 1/5\n",
      " - 153s - loss: 0.6902 - acc: 0.5270 - val_loss: 0.6507 - val_acc: 0.5656\n",
      "Epoch 2/5\n",
      " - 151s - loss: 0.5031 - acc: 0.7735 - val_loss: 0.4702 - val_acc: 0.7778\n",
      "Epoch 3/5\n",
      " - 139s - loss: 0.2385 - acc: 0.9195 - val_loss: 0.5416 - val_acc: 0.7640\n",
      "Epoch 4/5\n",
      " - 146s - loss: 0.1182 - acc: 0.9650 - val_loss: 0.6447 - val_acc: 0.7674\n",
      "Epoch 5/5\n",
      " - 152s - loss: 0.0550 - acc: 0.9848 - val_loss: 0.9080 - val_acc: 0.7585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e25ec0eb8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad,y_train, epochs=5, validation_data=(x_test_pad,y_test), verbose=2, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 7. MODEL EVALUATION AND SELECTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> The accuracy scores of all the models are as follows:\n",
    "    \n",
    "    LOGISTIC REGRESSION MULTI-CLASS - 53%\n",
    "    LOGISTIC REGRESSION BINARY - 71.7%\n",
    "    KERAS SEQUENTIAL MULTICLASS - 62%\n",
    "    KERAS SEQUENTIAL BINARY - 75.8%\n",
    "\n",
    "    The best performance is that of binary keras sequential model with an accuracy score of almost 76%. Lets test this with new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 8. TESTING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved an accuracy of 76%. Let's test the model with sample negative and positive comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample1='kya pagal insan ho, jao yahan se' #negative\n",
    "test_sample2='mujhe ye bht pasand hai' #positive\n",
    "test_sample3='mujhe ye bura lagraha hai'#negative\n",
    "test_sample4='mei khush hon' #positive\n",
    "test_sample5='mei bht dukhi hon' #negative\n",
    "\n",
    "samples=[test_sample1,test_sample2,test_sample3,test_sample4,test_sample5]\n",
    "samples_tokens=tokenizer_obj.texts_to_sequences(samples)\n",
    "samples_tokenspad=pad_sequences(samples_tokens, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02842337],\n",
       "       [0.70118   ],\n",
       "       [0.38772053],\n",
       "       [0.799471  ],\n",
       "       [0.62193364]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x=samples_tokenspad)   #a value close to zero is negative, a value close to one is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We find that the model performs well on the first four samples but incorrect for the 5th sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
